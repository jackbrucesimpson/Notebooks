{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification based on item attributes\n",
    "Problems with collaborative filters:\n",
    "- Data sparsity and scaling\n",
    "- Bias towards things that are already popular\n",
    "\n",
    "Instead, we can build a recommendation system that uses the features within the items themselves to identify similar items and recommend them. Pandora defines different attributes for songs (jazz, rap, etc) and rates them on a 1-5 scale with 0.5 increments. Attributes are arranged into categories - there's a category for attributes associated with Blues rock, folk rock and pop rock etc. Another category is instruments: accordian, dirty electric guitar riffs and the use of dirty sounding organs.\n",
    "\n",
    "## Euclidean Distance\n",
    "Pandora represents each song as a vector of 400 numeric values and can use this to make recommendations. With this information, we can calculate the Euclidean distance between songs and identify similar ones to recommend. However, this can lead to problems as songs will be classified as similar based on the absense of certain features. Therefore we need to focus on what songs have in common at the high end of the scale.\n",
    "\n",
    "## Normalisation\n",
    "If we add a new feature - beats per minute - then it can be problematic for our distance metric as bpm dominates the calculation. Another example could be a dating site where the best attributes to match people were salary and age. The age range is much lower than the salary range. One solution is normalisation.\n",
    "\n",
    "A common normalisation technique is to have the values of each feature range from 0-1. If the min salary is \\$43,000 and the max is \\$115,000, the range is \\$72,000. To convert a value (75,000) to the scale we subtract the min from the value and divide by the range.\n",
    "\n",
    "(75,000-43000) / 72000 = 0.444\n",
    "\n",
    "## Standard Score / Z Score\n",
    "Tells us how many deviations a value is from the mean. Standardizing the score involves minusing each value from the mean and dividing it by the standard deviation.\n",
    "\n",
    "$$\n",
    "sd = \\sqrt{\\frac{\\sum_i(x_i - \\bar{x})^2}{card(x)}}\n",
    "$$\n",
    "\n",
    "card(x) is the number of values there are.\n",
    "\n",
    "## Problems with the standard score\n",
    "The standard score is strongly influenced by outliers. Instead we can use the **modified standard score**. Here you replace the mean with the median and replace the standard deviation with the absolute standard deviation.\n",
    "\n",
    "## Modified Standard Score\n",
    "each value - median / absolute standard deviation\n",
    "\n",
    "$$\n",
    "abs = \\frac{1}{card(x)}\\sum_i|x_i - \\mu|\n",
    "$$\n",
    "\n",
    "## Why Normalise\n",
    "Normalisation makes sense when the scales of different features differs significantly.  If your features have a similar range, it probably isn't worth it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
